> Consider the tridiagonal matrix
>
> $$
> A =
> \begin{pmatrix}
>  1 & -1 &  0 &  0 &  0 \\\\
> -1 &  2 & -1 &  0 &  0 \\\\
>  0 & -1 &  2 & -1 &  0 \\\\
>  0 &  0 & -1 &  2 & -1 \\\\
>  0 &  0 &  0 & -1 &  2
> \end{pmatrix}.
> $$
>
> **a.** Find an $\text{LU}$ decomposition of $A$.
>
> **b.** Solve the equation $Ax = \begin{pmatrix} 1 & 1 & 1 & 1 & 1 \end{pmatrix}^{\text T}$ by using forward and back substitution.
>
> **c.** Find the inverse of $A$.
>
> **d.** Show how, for any $n \times n$ symmetric positive-definite, tridiagonal matrix $A$ and any $n$-vector $b$, to solve the equation $Ax = b$ in $O(n)$ time by performing an $\text{LU}$ decomposition. Argue that any method based on forming $A^{-1}$ is asymptotically more expensive in the worst case.
>
> **e.** Show how, for any $n \times n$ nonsingular, tridiagonal matrix $A$ and any $n$-vector $b$, to solve the equation $Ax = b$ in $O(n)$ time by performing an $\text{LUP}$ decomposition.

(Omit!)
