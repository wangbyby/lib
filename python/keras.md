# çŒ«ç‹—å¤§æˆ˜
å³ä½¿ç”¨kerasåº“è®­ç»ƒæ¨¡å‹,ç„¶åè¯†åˆ«çŒ«ç‹—å›¾ç‰‡/ç…§ç‰‡
# kerasç®€ä»‹
Keras æ˜¯ä¸€ä¸ªç”¨ Python ç¼–å†™çš„é«˜çº§ç¥ç»ç½‘ç»œ APIï¼Œå®ƒèƒ½å¤Ÿä»¥ TensorFlow, CNTK, æˆ–è€… Theano ä½œä¸ºåç«¯è¿è¡Œã€‚Keras çš„å¼€å‘é‡ç‚¹æ˜¯æ”¯æŒå¿«é€Ÿçš„å®éªŒã€‚èƒ½å¤Ÿä»¥æœ€å°çš„æ—¶å»¶æŠŠä½ çš„æƒ³æ³•è½¬æ¢ä¸ºå®éªŒç»“æœï¼Œæ˜¯åšå¥½ç ”ç©¶çš„å…³é”®ã€‚
å¦‚æœä½ åœ¨ä»¥ä¸‹æƒ…å†µä¸‹éœ€è¦æ·±åº¦å­¦ä¹ åº“ï¼Œè¯·ä½¿ç”¨ Kerasï¼š
    å…è®¸ç®€å•è€Œå¿«é€Ÿçš„åŸå‹è®¾è®¡ï¼ˆç”±äºç”¨æˆ·å‹å¥½ï¼Œé«˜åº¦æ¨¡å—åŒ–ï¼Œå¯æ‰©å±•æ€§ï¼‰ã€‚
    åŒæ—¶æ”¯æŒå·ç§¯ç¥ç»ç½‘ç»œå’Œå¾ªç¯ç¥ç»ç½‘ç»œï¼Œä»¥åŠä¸¤è€…çš„ç»„åˆã€‚
    åœ¨ CPU å’Œ GPU ä¸Šæ— ç¼è¿è¡Œã€‚
**Keras å…¼å®¹çš„ Python ç‰ˆæœ¬: Python 2.7-3.6ã€‚**
[kerasæ–‡æ¡£](https://keras.io/zh/)
# Pythonä¸­å®‰è£…kerasåº“
    - å…ˆå‰å‡†å¤‡
        åœ¨å®‰è£…Kerasä¹‹å‰ï¼Œè¯·å®‰è£…ä»¥ä¸‹åç«¯ä¹‹ä¸€ï¼šTensorFlowï¼ŒTheanoï¼Œæˆ–è€… CNTKã€‚æ¨èä½¿ç”¨TensorFlowåç«¯ã€‚
    - å®‰è£…TensorFlow
        ```bash
        pip install --upgrade --ignore-installed tensorflow
        ```
        ä¸‹è½½çš„å¾ˆæ…¢,è€å¿ƒç­‰å¾…
    - ç¡®è®¤Tensorflowå®‰è£…æˆåŠŸ
    - å®‰è£…keras
        ```bash
        pip install keras
        ```
    - éªŒè¯å®‰è£…


# keraså®æˆ˜
**çŒ«ç‹—å¤§æˆ˜**
* [è®­ç»ƒé›†ä»¥åŠæµ‹è¯•é›†è¿æ¥](https://pan.baidu.com/s/1EGgAAyEyEt5BPfNodaq6Rg)
* è®­ç»ƒé›†è¯´æ˜
    å¤§æ¦‚æ˜¯ä¸€ä¸‡å¤šå¼ å›¾ç‰‡,æˆ‘åªç”¨äº†ä¸åˆ°ä¸€åŠçš„å›¾ç‰‡æ¥è®­ç»ƒ

* é¡¹ç›®åŠŸèƒ½
    å…ˆè®­ç»ƒ,ç„¶åè¯†åˆ«çŒ«ç‹—å›¾ç‰‡
* é¡¹ç›®ç›®å½•
* è®­ç»ƒç»“æœ
* ç¤ºä¾‹ç¨‹åº
```python
#utf-8
from __future__ import print_function
import keras
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.preprocessing import  image
import  numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import random
import matplotlib as mpl
from matplotlib.image import imread


batch_size = 128
num_classes = 10
epochs = 12#æ¬¡æ•°
img_rows, img_cols = 28, 28
classs1 = {1:'ç‹—',0:'çŒ«'}
classes2={'cat':0,'dog':1}
"""
trainæ–‡ä»¶å¤¹ä¸‹
    0 : çŒ«ğŸ±
    1 : ç‹—ğŸ•
"""
#æ–‡ä»¶è½¬æ¢ä¸º np æ•°ç»„ ç”¨äºpredict
def image_file_nparray(image_path, width=100,height=100):
    img = image.load_img(image_path, target_size=(width,height))
    img = image.img_to_array(img)
    x = np.expand_dims(img, axis=0)
    return x
#è£å‰ªå•ä¸ªå›¾ç‰‡
def convert_one_image(file_path,width=100,height=100):
    img = Image.open(file_path)
    try:
        new_img = img.resize((width,height), Image.BILINEAR)
        new_img.save(file_path)
    except Exception as e:
        print("convert image error")
        print(e)
#å‰ªè£æ”¹ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡
#ç”¨äºäºŒçº§ç›®å½•
def convert_all_images(all_images_path):
    first_dir = os.listdir(all_images_path)

    for i in first_dir:
        _file_path = all_images_path + '/' + i
        if os.path.isdir(_file_path): #æ˜¯ç›®å½•    
            file_list = os.listdir(_file_path)
            for j in file_list:
                path_image = _file_path + '/' + j
                convert_one_image(path_image)  # è½¬æ¢
        else: #ä¸æ˜¯ç›®å½•, ç›´æ¥è½¬æ¢
            convert_one_image(_file_path)  # è½¬æ¢
# imageè½¬æ¢ä¸º np æ•°ç»„, ç”¨äº è®­ç»ƒæ¨¡å‹
def images_nparray(all_images_path):
    import os
    _x = []
    _y = []
    for i in os.listdir(all_images_path):
        _file_path = all_images_path+'/'+i
        if os.path.isdir(_file_path):#æ˜¯ç›®å½•

            for j in os.listdir(_file_path):
                y_label = j.split('_')[0]
                _y.append(y_label)

                path_image = _file_path +'/'+ j

                #å›¾ç‰‡åˆ°npæ•°ç»„
                img__ = Image.open(path_image).convert('RGB')
                img__ = np.array(img__)
                _x.append(img__)

        #ä¸æ˜¯ç›®å½•
        else:
            y_label = i.split('.')[0]
            y_label = classes2[y_label]
            print(y_label)
            _y.append(y_label)
            path_image = _file_path
            img__ = Image.open(path_image).convert('RGB')
            img__ = np.array(img__)
            _x.append(img__)
    return np.array(_x), np.array(_y)
# npæ•°ç»„ è½¬æ¢ä¸º npzæ–‡ä»¶
def nparray_to_npz(train_path, test_path,npz_file_path):
    convert_all_images(train_path)
    convert_all_images(test_path)
    x_train,y_train = images_nparray(train_path)
    x_test,y_test = images_nparray(test_path)
    #ä¿å­˜å‹ç¼©æ–‡ä»¶
    np.savez(npz_file_path, x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test)
#è®­ç»ƒå‡½æ•°
def running_train_test(npz_file_path, save_file_path):
    input_shape = (100,100,3)
    # the data, split between train and test sets
    data = np.load(npz_file_path)
    x_train, y_train, x_test, y_test = data['x_train'],data['y_train'],data['x_test'],data['y_test']

    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')
    x_train /= 255
    x_test /= 255
    print('x_train shape:', x_train.shape)
    print(x_train.shape[0], 'train samples')
    print(x_test.shape[0], 'test samples')
    # convert class vectors to binary class matrices
    y_train = keras.utils.to_categorical(y_train, num_classes)
    y_test = keras.utils.to_categorical(y_test, num_classes)

    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3),
                        activation='relu',
                        input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(loss=keras.losses.categorical_crossentropy,
                    optimizer=keras.optimizers.Adadelta(),
                    metrics=['accuracy'])


    hist = model.fit(x_train, y_train,
                batch_size=batch_size,
                epochs=epochs,
                verbose=1,
                validation_data=(x_test, y_test))
    score = model.evaluate(x_test, y_test, verbose=0)
    print('Test loss:', score[0])
    print('Test accuracy:', score[1])
    model.save(save_file_path) #ä¿å­˜
    #ç»˜å›¾
    plt.figure()
    print(hist.history)
    acc = hist.history['accuracy'] # è¯·æ³¨æ„historyçš„ç»“æ„æœ‰æ²¡æœ‰å˜åŒ–
    val_acc = hist.history['val_accuracy']
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    epochs2 = range(len(acc))
    plt.plot(epochs2, acc, 'bo', label='Training acc')  # 'bo'ä¸ºç”»è“è‰²åœ†ç‚¹ï¼Œä¸è¿çº¿
    plt.plot(epochs2, val_acc, 'b', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()  # ç»˜åˆ¶å›¾ä¾‹ï¼Œé»˜è®¤åœ¨å³ä¸Šè§’
    plt.figure()
    plt.plot(epochs2, loss, 'bo', label='Training loss')
    plt.plot(epochs2, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()

    plt.show()

# è½¬æ¢ä¸è®­ç»ƒ
def train_test_images_to_model(train, test, npz_path, h5_path):
    nparray_to_npz(train,test,npz_path)
    running_train_test(npz_path,h5_path)
# ç”¨äºé¢„æµ‹
def load_model_from_h5_and_predict(h5_path, pre_path):
    model = load_model(h5_path)
    # convert_one_image(pre_path)
    pre_nparray = image_file_nparray(pre_path)
    pre_y = model.predict_classes(pre_nparray)
    print("ç»“æœ : ",classs1[pre_y[0]])
    return classs1[pre_y[0]]

def predict_one_file(model, pre_path):
    pre_nparray = image_file_nparray(pre_path)
    pre_y = model.predict_classes(pre_nparray)
    print("ç»“æœ : ", classs1[pre_y[0]])
    return classs1[pre_y[0]]
def predict_dir_images(h5_path, pre_path, num=10):
    model = load_model(h5_path)
    res = []
    mpl.rcParams['font.sans-serif'] = ['FangSong']  # æŒ‡å®šé»˜è®¤å­—ä½“
    mpl.rcParams['axes.unicode_minus'] = False  # è§£å†³ä¿å­˜å›¾åƒæ˜¯è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
    for i in range  (num):
        imgpath =  random.randint(1,10000)
        imgpath = pre_path+"/"+str(imgpath)+".jpg"
        tmp = predict_one_file(model,imgpath)
        res.append({"file":imgpath,"result":tmp})
        img = imread(imgpath)
        plt.subplot(2,5,i+1)
        plt.title(imgpath+" : "+tmp)
        plt.imshow(img)
    return res


#mainå‡½æ•°
if "__main__" == __name__:
    npz_path = 'cat_dog.npz'
    save_path = 'save.h5'
    test_dir_path = 'test'
    train_dir_path = 'train'
    pre = 'pre'
    #1. è¦è®­ç»ƒæ•°æ®æ—¶,æ‰§è¡Œtrain_test_images_to_modelå‡½æ•°
    # train_test_images_to_model(train_dir_path, test_dir_path, npz_path, save_path)
    #2. è¯†åˆ«å›¾ç‰‡æ—¶,æ‰§è¡Œpredict_dir_imageså‡½æ•°
    res = predict_dir_images(save_path,pre)
    plt.show()
    print(res)

```
* å‚è€ƒèµ„æ–™
	1. kaggleæ•°æ®é›†
æ•°æ®é›†åˆ†ä¸º è®­ç»ƒé›†å’Œæµ‹è¯•é›†, æ•°æ®é›†æ˜¯è‡ªå·±ä»ç½‘ä¸Šæ‰¾çš„. Kaggleçš„ä¸‹è½½é€Ÿåº¦å¤ªæ…¢,æ‰€ä»¥ç”¨ç™¾åº¦ç½‘ç›˜æ›¿ä»£.
		ç½‘å€ : https://pan.baidu.com/s/1EGgAAyEyEt5BPfNodaq6Rg
	2. å‚è€ƒèµ„æ–™
		- åˆ©ç”¨kerasè¿›è¡Œå›¾åƒè¯†åˆ«â€”â€”è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†, https://blog.csdn.net/yh_1021/article/details/83041275
		- 	ã€æ·±åº¦å­¦ä¹ æ¡†æ¶Kerasã€‘åœ¨å°æ•°æ®é›†ä¸Šè®­ç»ƒå›¾ç‰‡åˆ†ç±»æ¨¡å‹çš„æŠ€å·§https://blog.csdn.net/bqw18744018044/article/details/83656320
		- 	Kerasï¼šè‡ªå»ºæ•°æ®é›†å›¾åƒåˆ†ç±»çš„æ¨¡å‹è®­ç»ƒã€ä¿å­˜ä¸æ¢å¤, https://blog.csdn.net/akadiao/article/details/80456742